---
title: "[week 7] Object Detection: YOLOv3~v4"
excerpt: "[week 7] Object Detection: YOLOv3~v4"
categories: [GDSC ML]
tags: [GDSC ML, Python]
toc: true
toc_sticky: true
---

## YOLO의 motivation

Fast core vision algorithms for "real-time application <br>

YOLO는 정확한 성능보다는 **_real-time application_** 을 위한 빠른 속도의 알고리즘에 초점 <br>

- YOLOv1: 빠른 속도, 낮은 정확도
- YOLOv2: v1 대비 속도, 성능 개선(small object 낮은 성능)
- YOLOv3: v2 대비 속도는 다소 느리지만, 성능은 개선(small object 성능 개선)
- YOLOv4: v3 대비 속도와 성능 개선

## YOLOv3

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/202841724-4a7ce018-c764-4514-83a4-17c330adc21d.png"> <br>

bx와 by를 예측하기 위해서는 모델의 output인 tx, ty에 시그모이드를 취하고 Cx와 Cy를 각각 더해주고 있다. => 범위 제한이 없는 tx, ty를 0~1 사이의 값으로 정규화 해줌으로써 bbox의 중심 좌표가 기준 cell을 넘어가지 않도록 해준다. <br>

### YOLOv3의 Loss

- B-box regression Loss: GT좌표과 bbox 좌표의 오차를 이용, GT와 width, height와 bbox의 width, height 오차를 이용
- Object Confidence Loss: 모델에서 구한 object class와 실제 class의 차이에 IoU를 곱해서 이용
- Classification Loss: 클래스별 확률값의 오차를 이용

### Bounding box prediction

<img width="504" alt="download3" src="https://user-images.githubusercontent.com/96654391/202842415-d592f2d2-a824-40a7-ad7f-42e317fc62ae.png"> <br>

cell 한 개에 대해서 9개의 Anchor box 예측 <br>

Anchor box의 size는 사전에 어떤 크기로 설정이 될까? <br>
GT의 w, h를 기준으로 K-means clustering를 진행하여 대푯값들을 지정을 하고, 그 대푯값의 가로, 세로 값을 Anchor box의 가로, 세로 값으로 설정한다. 위 그림은 Anchor box를 5개를 예측했지만 이는 v2에 해당하는 그림이고 실제로는 9개의 Anchor box를 예측한다. <br>

**k-means Clustering** <br>
k means clustering은 입력값으로 k를 취하고 객체 집합을 k개의 클러스터로 만드는 방법이다. 클러스터 내 유사성은 높게, 클러스터 간 유사성은 낮게해야 좋은 분류가 이루어진다. <br>

<center><img width="500" alt="download2" src="https://user-images.githubusercontent.com/96654391/202842296-858864b3-68ba-4393-82c9-55c70e729fb5.png"></center>

### Class Prediction

Multi Label에 대한 예측 성능을 높이기 위해 class prediction 과정에 변화를 주었다. Multi Label / Multi class란 사람이라고도 읽을 수 있고, 여자라고도 읽을 수 있는 경우를 얘기를 한다. <br>

논문에서는 softmax classifier을 통해서 단 하나의 클래스만을 찾도록 하니 성능 향상에 도움이 되지 않았다고 했다. 따라서 저자는 각 클래스가 맞는지 아닌지를 찾도록 하는 Binary Classification 문제로 바꾸어서 접근을 하였다. = Logistic classifier, Binary Cross Entropy를 사용

### Feature Extractor

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/202842669-35df18e4-afd8-4705-871f-97fb35eb835f.png"> <br>

Darknet-19에 ResNet 아이디어를 더해서 Darknet-53을 만들게 되었다. => Darknet019보다 높은 성능을 가지며, ResNet101, ResNet152 구조 대비 대등한 성능 및 효율적인 연산을 가지고 있다.

### YOLOv3 Model structure

<img width="1000" alt="download2" src="https://user-images.githubusercontent.com/96654391/202842789-c1b5c777-ae5f-4573-b0ce-62b3ca436f53.png"> <br>

input image(608x608) <br>
-> Feature Extractor인 Darknet53 통과(downsampling) <br>
-> 19x19에서 최초로 detection 진행 <br>
-> (upsampling & detection) \* 2 <br>
-> 3개의 스케일의 피쳐맵에서 각기 수행이 되는데 이런 과정을 통해서 Multi scale object detection 성능을 높이게 된다

### Output Feature Map

<img width="1000" alt="download3" src="https://user-images.githubusercontent.com/96654391/202842979-a4d94275-95b0-4b6c-98c6-d7127c1cb802.png"> <br>

v2와 유사하게 하나의 bbox에 대해서 tx, ty, tw, th, P, Class Score의 채널(깊이)를 가진 feature map이 3개가 있게 된다. <br>
❓v2에서는 bbox와 Objectness score에 대한 정보가 cell 당 2개씩 진행이 되었고 Class Scores는 cell 당 한 묶음이 나오게 되었는데, v3에서는 bbox당 Class Scores가 나오는게 Logistic Regression을 사용해서 그런게 맞아? <br>
🖐️ 그게 아니고, 3개의 스케일에 대해서 훈련을 하였기 때문인듯?

### Experiments

- SSD 계열인 DSSD와 유사한 AP성능을 보이면서 속도는 3배 빠름
- APs(small object에 대한 정확도)에 대한 성능이 v2에 비해 약 3배 높아진 것을 확인
- RetinalNet을 제외한 다른 모델에 대해서 AP성능이 대부분 높거나, 상단을 이루는 것을 확인

### YOLOv3과 이전 버전 비교

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/202843363-d44e25b8-1225-4b6a-9260-9b33d79eb00d.png">

## YOLOv4

v3이후 object detection 관련 많은 기법이 나왔다. 그런 것들 중 v3에 추가적으로 적용해서 v3를 개선하고자 나오게 되었다.

### Related Works

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/202846246-3a9bc39f-6c93-4344-9bb3-7e4db7c79279.png"> <br>

- BoF(Bag of Freebies): 효과적이고 효율적인 학습을 위한 기법들
- BoS(Bag of Sepcials): 정확도 향상을 위한 추가 모듈 기법 및 후처리 방법

### Methodology

- 작은 물체를 탐지하기 위해 더 큰 해상도 이미지(512x512)
- 큰 해상도 이미지를 다루기 위해 더 많은 Layer로 큰 receptive field
- 다양한 크기의 물체를 탐지하기 위해 더 큰 capacity 모델 <br>

BoF와 Bos 중 기법들을 선택하여 실험한 리스트와 초록색 색깔의 글씨는 최종적으로 선택하여 사용한 기법이다. <br>

<img width="1000" alt="download2" src="https://user-images.githubusercontent.com/96654391/202846448-498f8aa3-6eed-4a15-959a-f075ae8ddb99.png">

<img width="1000" alt="download3" src="https://user-images.githubusercontent.com/96654391/202846531-1b268d06-637f-4271-9b9b-45bcb570d1c2.png"> <br>

- Mosaic: 여러 이미지를 이어 붙혀서 한 장의 이미지로 사용하는 것이다. => Batch size가 4인 효과를 두어서 적은 batch size로 같은 효과를 낼 수 있다.
- Modified SAM, Modified PAN <br>
  <img width="700" alt="download2" src="https://user-images.githubusercontent.com/96654391/202846657-92cfccac-5e98-4723-8f8a-098623339bbe.png"> <br>
  근데 이를 적용한 구체적인 이유는 나와있지 않았다고 한다.
- Cross mini-Batch Normalization <br>
  <img width="700" alt="download3" src="https://user-images.githubusercontent.com/96654391/202846765-1b76421c-8008-4817-b4f3-95540d968470.png"> <br>
  mini batch 단위로 batch를 정규화한 것 <br>
  <br>

최종적으로 <br>

- Backbone: CSPDarknet53
- Neck: SPP, PAN
- Head: YOLOv3
