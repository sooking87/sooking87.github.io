---
title: "[chap 9-3] LSTMÍ≥º GRU ÏÖÄ"
excerpt: "[chap 9-3] LSTMÍ≥º GRU ÏÖÄ"
categories: [Ai Study]
tags: [Ai Study, Python]
toc: true
toc_sticky: true
---

üìå Ïïû Ï†àÏóêÏÑú Î∞∞Ïõ†Îçò SimpleRNNÎ≥¥Îã§ Í≥ÑÏÇ∞Ïù¥ Ìõ®Ïî¨ Î≥µÏû°ÌïòÏßÄÎßå ÏÑ±Îä•Ïù¥ Îõ∞Ïñ¥ÎÇòÍ∏∞ ÎïåÎ¨∏Ïóê ÏàúÌôò Ïã†Í≤ΩÎßùÏóê ÎßéÏù¥ Ï±ÑÌÉùÎêòÍ≥† ÏûàÎã§.

## üîÆ LSTM Íµ¨Ï°∞

LSTMÏùÄ Long Short-Term MemoryÏùò ÏïΩÏûêÎ°ú Îßê Í∑∏ÎåÄÎ°ú Îã®Í∏∞ Í∏∞ÏñµÏùÑ Ïò§Îûò Í∏∞ÏñµÌïòÍ∏∞ ÏúÑÌï¥ Í≥†ÏïàÎêòÏóàÎã§.

### üìç ÏùÄÎãâ ÏÉÅÌÉú ÎßåÎìúÎäî Î∞©Î≤ï

ÏûÖÎ†•Í≥º Ïù¥Ï†Ñ ÌÉÄÏûÑÏä§ÌÖùÏùò ÏùÄÎãâ ÏÉÅÌÉúÎ•º Í∞ÄÏ§ëÏπòÏóê Í≥±Ìïú ÌõÑ ÌôúÏÑ±Ìôî Ìï®ÏàòÎ•º ÌÜµÍ≥ºÏãúÏºú Îã§Ïùå ÏùÄÎãâ ÏÉÅÌÉúÎ•º ÎßåÎì†Îã§.

### üìç ÏÖÄ ÏÉÅÌÉú ÎßåÎìúÎäî Î∞©Î≤ï

LSTMÏóêÎäî ÏàúÌôòÎêòÎäî ÏÉÅÌÉúÍ∞Ä 2Í∞úÏù∏Îç∞ ÏùÄÎãâ ÏÉÅÌÉú ÎßêÍ≥† **_ÏÖÄ ÏÉÅÌÉú_** ÎùºÍ≥† Î∂ÄÎ•¥Îäî Í∞íÏù¥ Îòê ÏûàÎã§. ÏÖÄ ÏÉÅÌÉúÎäî Îã§Ïùå Ï∏µÏúºÎ°ú Ï†ÑÎã¨ÎêòÏßÄ ÏïäÍ≥† LSTM ÏÖÄÏóêÏÑú ÏàúÌôòÎßå ÎêòÎäî Í∞íÏù¥Îã§. ÏÖÄ ÏÉÅÌÉúÎäî ÏûÖÎ†•Í≥º ÏùÄÎãâ ÏÉÅÌÉúÎ•º Îòê Îã§Î•∏ Í∞ÄÏ§ëÏπòÏôÄ Í≥±Ìïú Îã§Ïùå ÏÖÄ ÏÉÅÌÉúÎ•º ÎßåÎì§Í∏∞ ÏúÑÌïú ÌïòÎÇòÏùò ÏÖÄÏùÄ ÏãúÍ∑∏Î™®Ïù¥Îìú Ìï®ÏàòÎ•º ÌÜµÍ≥ºÏãúÌÇ§Í≥†, Îã§Î•∏ ÏÖÄÏùÄ tanh Ìï®ÏàòÎ•º ÌÜµÍ≥ºÏãúÌÇµÎãàÎã§. Í∑∏ Îã§Ïùå Ïù¥Ï†Ñ ÌÉÄÏûÑÏä§ÌÖùÏùò ÏÖÄ ÏÉÅÌÉúÏôÄ Í≥±ÌïòÏó¨ ÏÉàÎ°úÏö¥ ÏÖÄ ÏÉÅÌÉúÎ•º ÎßåÎì†Îã§.

### 1Ô∏è‚É£ Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞

```python
from tensorflow.keras.datasets import imdb
from sklearn.model_selection import train_test_split

(train_input, train_target), (test_input, test_target) = imdb.load_data(num_words=500)

train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)

from tensorflow.keras.preprocessing.sequence import pad_sequences

train_seq = pad_sequences(train_input, maxlen=100)
val_seq = pad_sequences(val_input, maxlen=100)
```

### 2Ô∏è‚É£ LSTM Ïã†Í≤ΩÎßù ÎßåÎì§Í∏∞

```python
from tensorflow import keras
model = keras.Sequential()
model.add(keras.layers.Embedding(500, 16, input_length=100))
model.add(keras.layers.LSTM(8))
model.add(keras.layers.Dense(1, activation='sigmoid'))
model.summary()

>>>
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_1 (Embedding)     (None, 100, 16)           8000

 lstm_1 (LSTM)               (None, 8)                 800

 dense_1 (Dense)             (None, 1)                 9

=================================================================
Total params: 8,809
Trainable params: 8,809
Non-trainable params: 0
_________________________________________________________________
```

SimpleRNN ÌÅ¥ÎûòÏä§ÏóêÏÑúÎäî ÏùÄÎãâ ÏÉÅÌÉú Ìïú Í∞úÏòÄÏúºÎØÄÎ°ú Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàòÍ∞Ä 200Í∞ú ÏòÄÏßÄÎßå LSTM ÏÖÄÏùÄ ÏûëÏùÄ ÏÖÄÏù¥ 4Í∞úÍ∞Ä ÏûàÏúºÎØÄÎ°ú 800Í∞úÏùò Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞Í∞Ä ÏûàÎäî Í≤ÉÏùÑ ÌôïÏù∏Ìï† Ïàò ÏûàÎã§.

### 3Ô∏è‚É£ LSTM Î™®Îç∏ ÌõàÎ†®ÌïòÍ∏∞

```python
rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)
model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])

checkpoint_cb = keras.callbacks.ModelCheckpoint('best-lstm-model.h5', save_best_only=True)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)

history = model.fit(train_seq, train_target, epochs=100, batch_size=64,validation_data=(val_seq, val_target),callbacks=[checkpoint_cb, early_stopping_cb])

>>>
Epoch 1/100
313/313 [==============================] - 18s 48ms/step - loss: 0.6925 - accuracy: 0.5555 - val_loss: 0.6919 - val_accuracy: 0.5940
Epoch 2/100
313/313 [==============================] - 13s 43ms/step - loss: 0.6908 - accuracy: 0.6041 - val_loss: 0.6898 - val_accuracy: 0.6162
Epoch 3/100
313/313 [==============================] - 16s 50ms/step - loss: 0.6875 - accuracy: 0.6321 - val_loss: 0.6852 - val_accuracy: 0.6356
Epoch 4/100
313/313 [==============================] - 13s 41ms/step - loss: 0.6803 - accuracy: 0.6495 - val_loss: 0.6753 - val_accuracy: 0.6576
Epoch 5/100
313/313 [==============================] - 12s 37ms/step - loss: 0.6637 - accuracy: 0.6744 - val_loss: 0.6500 - val_accuracy: 0.6912
Epoch 6/100
313/313 [==============================] - 12s 37ms/step - loss: 0.6107 - accuracy: 0.7127 - val_loss: 0.5773 - val_accuracy: 0.7266
Epoch 7/100
313/313 [==============================] - 14s 45ms/step - loss: 0.5573 - accuracy: 0.7405 - val_loss: 0.5515 - val_accuracy: 0.7436
Epoch 8/100
313/313 [==============================] - 14s 45ms/step - loss: 0.5347 - accuracy: 0.7538 - val_loss: 0.5326 - val_accuracy: 0.7508
Epoch 9/100
313/313 [==============================] - 14s 43ms/step - loss: 0.5163 - accuracy: 0.7645 - val_loss: 0.5173 - val_accuracy: 0.7650
Epoch 10/100
313/313 [==============================] - 13s 41ms/step - loss: 0.5004 - accuracy: 0.7741 - val_loss: 0.5026 - val_accuracy: 0.7676
Epoch 11/100
313/313 [==============================] - 12s 40ms/step - loss: 0.4862 - accuracy: 0.7837 - val_loss: 0.4893 - val_accuracy: 0.7810
Epoch 12/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4734 - accuracy: 0.7890 - val_loss: 0.4780 - val_accuracy: 0.7840
Epoch 13/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4621 - accuracy: 0.7944 - val_loss: 0.4696 - val_accuracy: 0.7868
Epoch 14/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4525 - accuracy: 0.7982 - val_loss: 0.4615 - val_accuracy: 0.7886
Epoch 15/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4440 - accuracy: 0.8022 - val_loss: 0.4529 - val_accuracy: 0.7924
Epoch 16/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4370 - accuracy: 0.8049 - val_loss: 0.4475 - val_accuracy: 0.7956
Epoch 17/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4311 - accuracy: 0.8080 - val_loss: 0.4440 - val_accuracy: 0.7948
Epoch 18/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4263 - accuracy: 0.8101 - val_loss: 0.4443 - val_accuracy: 0.7918
Epoch 19/100
313/313 [==============================] - 11s 37ms/step - loss: 0.4227 - accuracy: 0.8106 - val_loss: 0.4380 - val_accuracy: 0.7982
Epoch 20/100
313/313 [==============================] - 11s 35ms/step - loss: 0.4198 - accuracy: 0.8116 - val_loss: 0.4369 - val_accuracy: 0.7978
Epoch 21/100
313/313 [==============================] - 12s 37ms/step - loss: 0.4176 - accuracy: 0.8135 - val_loss: 0.4357 - val_accuracy: 0.7984
Epoch 22/100
313/313 [==============================] - 11s 35ms/step - loss: 0.4153 - accuracy: 0.8141 - val_loss: 0.4368 - val_accuracy: 0.7994
Epoch 23/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4137 - accuracy: 0.8126 - val_loss: 0.4340 - val_accuracy: 0.7960
Epoch 24/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4122 - accuracy: 0.8140 - val_loss: 0.4334 - val_accuracy: 0.8018
Epoch 25/100
313/313 [==============================] - 11s 35ms/step - loss: 0.4109 - accuracy: 0.8137 - val_loss: 0.4331 - val_accuracy: 0.8032
Epoch 26/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4100 - accuracy: 0.8140 - val_loss: 0.4342 - val_accuracy: 0.8026
Epoch 27/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4091 - accuracy: 0.8140 - val_loss: 0.4323 - val_accuracy: 0.8000
Epoch 28/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4083 - accuracy: 0.8127 - val_loss: 0.4324 - val_accuracy: 0.8022
Epoch 29/100
313/313 [==============================] - 11s 36ms/step - loss: 0.4072 - accuracy: 0.8156 - val_loss: 0.4324 - val_accuracy: 0.7966
Epoch 30/100
313/313 [==============================] - 11s 37ms/step - loss: 0.4068 - accuracy: 0.8148 - val_loss: 0.4326 - val_accuracy: 0.7966
```

```python
import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train','val'])
plt.show()
```

![download1](https://user-images.githubusercontent.com/96654391/176167567-d70293ca-49ac-4900-86b0-c2247fd73cd6.png)

## üîÆ ÏàúÌôòÏ∏µÏóê ÎìúÎ°≠ÏïÑÏõÉ Ï†ÅÏö©ÌïòÍ∏∞

dropout Îß§Í∞úÎ≥ÄÏàòÎäî ÏÖÄÏùò ÏûÖÎ†•Ïóê ÎìúÎ°≠ÏïÑÏõÉÏùÑ Ï†ÅÏö©ÌïòÍ≥†, recurrent_dropout Îß§Í∞úÎ≥ÄÏàòÎäî ÏàúÌôòÎêòÎäî ÏùÄÎãâ ÏÉÅÌÉúÏóê ÎìúÎ°≠ÏïÑÏõÉÏùÑ Ï†ÅÏö©ÌïúÎã§.
<br>

### 2Ô∏è‚É£ Ïã†Í≤ΩÎßù ÎßåÎì§Í∏∞

ÎìúÎ°≠ ÏïÑÏõÉ 30% ÏßÄÏ†ï

```python
model2 = keras.Sequential()

model2.add(keras.layers.Embedding(500, 16, input_length=100))
model2.add(keras.layers.LSTM(8, dropout=0.3))
model2.add(keras.layers.Dense(1, activation='sigmoid'))
```

### 3Ô∏è‚É£ Ïã†Í≤ΩÎßù ÌõàÎ†®ÌïòÍ∏∞

```python
rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)
model2.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])

checkpoint_cb = keras.callbacks.ModelCheckpoint('best-dropout-model.h5', save_best_only=True)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)

history = model2.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb])

>>>
Epoch 1/100
313/313 [==============================] - 15s 40ms/step - loss: 0.6926 - accuracy: 0.5268 - val_loss: 0.6919 - val_accuracy: 0.5514
Epoch 2/100
313/313 [==============================] - 12s 38ms/step - loss: 0.6900 - accuracy: 0.5969 - val_loss: 0.6883 - val_accuracy: 0.5992
Epoch 3/100
313/313 [==============================] - 12s 37ms/step - loss: 0.6808 - accuracy: 0.6472 - val_loss: 0.6684 - val_accuracy: 0.6792
Epoch 4/100
313/313 [==============================] - 12s 38ms/step - loss: 0.6275 - accuracy: 0.7081 - val_loss: 0.5962 - val_accuracy: 0.7198
Epoch 5/100
313/313 [==============================] - 12s 38ms/step - loss: 0.5830 - accuracy: 0.7215 - val_loss: 0.5666 - val_accuracy: 0.7364
Epoch 6/100
313/313 [==============================] - 12s 39ms/step - loss: 0.5532 - accuracy: 0.7380 - val_loss: 0.5377 - val_accuracy: 0.7564
Epoch 7/100
313/313 [==============================] - 12s 39ms/step - loss: 0.5273 - accuracy: 0.7559 - val_loss: 0.5149 - val_accuracy: 0.7640
Epoch 8/100
313/313 [==============================] - 12s 39ms/step - loss: 0.5051 - accuracy: 0.7672 - val_loss: 0.4952 - val_accuracy: 0.7746
Epoch 9/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4889 - accuracy: 0.7750 - val_loss: 0.4792 - val_accuracy: 0.7848
Epoch 10/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4741 - accuracy: 0.7847 - val_loss: 0.4682 - val_accuracy: 0.7876
Epoch 11/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4645 - accuracy: 0.7895 - val_loss: 0.4612 - val_accuracy: 0.7894
Epoch 12/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4582 - accuracy: 0.7931 - val_loss: 0.4557 - val_accuracy: 0.7962
Epoch 13/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4517 - accuracy: 0.7965 - val_loss: 0.4510 - val_accuracy: 0.7940
Epoch 14/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4476 - accuracy: 0.7961 - val_loss: 0.4488 - val_accuracy: 0.7970
Epoch 15/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4448 - accuracy: 0.7992 - val_loss: 0.4492 - val_accuracy: 0.7928
Epoch 16/100
313/313 [==============================] - 12s 37ms/step - loss: 0.4406 - accuracy: 0.8019 - val_loss: 0.4451 - val_accuracy: 0.7936
Epoch 17/100
313/313 [==============================] - 12s 37ms/step - loss: 0.4370 - accuracy: 0.8034 - val_loss: 0.4412 - val_accuracy: 0.7984
Epoch 18/100
313/313 [==============================] - 12s 37ms/step - loss: 0.4344 - accuracy: 0.8027 - val_loss: 0.4414 - val_accuracy: 0.7970
Epoch 19/100
313/313 [==============================] - 13s 41ms/step - loss: 0.4329 - accuracy: 0.8033 - val_loss: 0.4375 - val_accuracy: 0.8006
Epoch 20/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4303 - accuracy: 0.8054 - val_loss: 0.4357 - val_accuracy: 0.8002
Epoch 21/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4290 - accuracy: 0.8061 - val_loss: 0.4343 - val_accuracy: 0.8024
Epoch 22/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4264 - accuracy: 0.8071 - val_loss: 0.4359 - val_accuracy: 0.8016
Epoch 23/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4248 - accuracy: 0.8100 - val_loss: 0.4333 - val_accuracy: 0.8022
Epoch 24/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4243 - accuracy: 0.8101 - val_loss: 0.4327 - val_accuracy: 0.8022
Epoch 25/100
313/313 [==============================] - 12s 38ms/step - loss: 0.4226 - accuracy: 0.8094 - val_loss: 0.4340 - val_accuracy: 0.8012
Epoch 26/100
313/313 [==============================] - 12s 37ms/step - loss: 0.4205 - accuracy: 0.8084 - val_loss: 0.4358 - val_accuracy: 0.8014
Epoch 27/100
313/313 [==============================] - 12s 37ms/step - loss: 0.4203 - accuracy: 0.8093 - val_loss: 0.4345 - val_accuracy: 0.7996
```

```python
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train','val'])
plt.show()
```

![download2](https://user-images.githubusercontent.com/96654391/176169065-c1c282fa-ed31-45a6-ac52-1ded0f8d172b.png)

LSTM Ï∏µÏóê Ï†ÅÏö©Ìïú ÎìúÎ°≠ÏïÑÏõÉÏù¥ Ìö®Í≥ºÎ•º Î∞úÌúòÌïòÏó¨ ÌõàÎ†® ÏÜêÏã§Í≥º Í≤ÄÏ¶ù ÏÜêÏã§ Í∞ÑÏùò Ï∞®Ïù¥Í∞Ä Ï¢ÅÌòÄÏßÑ Í≤ÉÏùÑ ÌôïÏù∏Ìï† Ïàò ÏûàÎã§.

## üîÆ 2Í∞úÏùò Ï∏µ Ïó∞Í≤∞ÌïòÍ∏∞

### 2Ô∏è‚É£ Ïã†Í≤ΩÎßù ÎßåÎì§Í∏∞

```python
model3 = keras.Sequential()

model3.add(keras.layers.Embedding(500, 16, input_length=100))
model3.add(keras.layers.LSTM(8, dropout=0.3, return_sequences=True))
model3.add(keras.layers.LSTM(8, dropout=0.3))
model3.add(keras.layers.Dense(1, activation='sigmoid'))

model3.summary()

>>>
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_3 (Embedding)     (None, 100, 16)           8000

 lstm_3 (LSTM)               (None, 100, 8)            800

 lstm_4 (LSTM)               (None, 8)                 544

 dense_3 (Dense)             (None, 1)                 9

=================================================================
Total params: 9,353
Trainable params: 9,353
Non-trainable params: 0
_________________________________________________________________
```

ÎßàÏßÄÎßâ ÏùÄÎãâ ÏÉÅÌÉúÎ•º Ï†úÏô∏Ìïú Î™®Îì† ÌÉÄÏûÑÏä§ÌÖùÏùò ÏùÄÎãâ ÏÉÅÌÉúÎ•º Ï∂úÎ†•ÌïòÎ†§Î©¥ **_return_sequences=True_** Î•º ÏßÄÏ†ïÌïòÎ©¥ ÎêúÎã§.

### 3Ô∏è‚É£ Ïã†Í≤ΩÎßù ÌõàÎ†®ÌïòÍ∏∞

```python
rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)
model3.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])

checkpoint_cb = keras.callbacks.ModelCheckpoint('best-2rnn-model.h5', save_best_only=True)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)

history = model3.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb])

>>>
313/313 [==============================] - 22s 72ms/step - loss: 0.4440 - accuracy: 0.7948 - val_loss: 0.4520 - val_accuracy: 0.7880
Epoch 24/100
313/313 [==============================] - 22s 71ms/step - loss: 0.4412 - accuracy: 0.7965 - val_loss: 0.4550 - val_accuracy: 0.7888
Epoch 25/100
313/313 [==============================] - 22s 71ms/step - loss: 0.4403 - accuracy: 0.7960 - val_loss: 0.4500 - val_accuracy: 0.7920
Epoch 26/100
313/313 [==============================] - 22s 72ms/step - loss: 0.4395 - accuracy: 0.7962 - val_loss: 0.4524 - val_accuracy: 0.7878
Epoch 27/100
313/313 [==============================] - 23s 73ms/step - loss: 0.4400 - accuracy: 0.7962 - val_loss: 0.4493 - val_accuracy: 0.7930
Epoch 28/100
313/313 [==============================] - 23s 74ms/step - loss: 0.4383 - accuracy: 0.7974 - val_loss: 0.4509 - val_accuracy: 0.7900
Epoch 29/100
313/313 [==============================] - 24s 77ms/step - loss: 0.4375 - accuracy: 0.7985 - val_loss: 0.4532 - val_accuracy: 0.7870
Epoch 30/100
313/313 [==============================] - 23s 73ms/step - loss: 0.4349 - accuracy: 0.8008 - val_loss: 0.4454 - val_accuracy: 0.7920
Epoch 31/100
313/313 [==============================] - 22s 72ms/step - loss: 0.4339 - accuracy: 0.8001 - val_loss: 0.4450 - val_accuracy: 0.7932
Epoch 32/100
313/313 [==============================] - 22s 71ms/step - loss: 0.4338 - accuracy: 0.8001 - val_loss: 0.4437 - val_accuracy: 0.7948
Epoch 33/100
313/313 [==============================] - 22s 70ms/step - loss: 0.4352 - accuracy: 0.7993 - val_loss: 0.4435 - val_accuracy: 0.7948
Epoch 34/100
313/313 [==============================] - 22s 70ms/step - loss: 0.4302 - accuracy: 0.8015 - val_loss: 0.4430 - val_accuracy: 0.7950
Epoch 35/100
313/313 [==============================] - 23s 72ms/step - loss: 0.4309 - accuracy: 0.8005 - val_loss: 0.4479 - val_accuracy: 0.7900
Epoch 36/100
313/313 [==============================] - 23s 73ms/step - loss: 0.4269 - accuracy: 0.8017 - val_loss: 0.4403 - val_accuracy: 0.7966
Epoch 37/100
313/313 [==============================] - 23s 73ms/step - loss: 0.4297 - accuracy: 0.8027 - val_loss: 0.4404 - val_accuracy: 0.7966
Epoch 38/100
313/313 [==============================] - 23s 73ms/step - loss: 0.4263 - accuracy: 0.8019 - val_loss: 0.4395 - val_accuracy: 0.7964
Epoch 39/100
313/313 [==============================] - 23s 73ms/step - loss: 0.4264 - accuracy: 0.8011 - val_loss: 0.4414 - val_accuracy: 0.7968
Epoch 40/100
313/313 [==============================] - 24s 77ms/step - loss: 0.4254 - accuracy: 0.8044 - val_loss: 0.4378 - val_accuracy: 0.7966
Epoch 41/100
313/313 [==============================] - 25s 79ms/step - loss: 0.4263 - accuracy: 0.8012 - val_loss: 0.4364 - val_accuracy: 0.7968
Epoch 42/100
313/313 [==============================] - 23s 75ms/step - loss: 0.4228 - accuracy: 0.8065 - val_loss: 0.4399 - val_accuracy: 0.7976
Epoch 43/100
313/313 [==============================] - 23s 73ms/step - loss: 0.4210 - accuracy: 0.8074 - val_loss: 0.4357 - val_accuracy: 0.7980
Epoch 44/100
313/313 [==============================] - 23s 72ms/step - loss: 0.4217 - accuracy: 0.8053 - val_loss: 0.4348 - val_accuracy: 0.7978
Epoch 45/100
313/313 [==============================] - 23s 72ms/step - loss: 0.4209 - accuracy: 0.8063 - val_loss: 0.4432 - val_accuracy: 0.7932
Epoch 46/100
313/313 [==============================] - 22s 72ms/step - loss: 0.4196 - accuracy: 0.8061 - val_loss: 0.4333 - val_accuracy: 0.8008
Epoch 47/100
313/313 [==============================] - 23s 72ms/step - loss: 0.4187 - accuracy: 0.8080 - val_loss: 0.4352 - val_accuracy: 0.7996
Epoch 48/100
313/313 [==============================] - 23s 72ms/step - loss: 0.4197 - accuracy: 0.8066 - val_loss: 0.4319 - val_accuracy: 0.8010
Epoch 49/100
313/313 [==============================] - 23s 74ms/step - loss: 0.4183 - accuracy: 0.8051 - val_loss: 0.4343 - val_accuracy: 0.8012
Epoch 50/100
313/313 [==============================] - 23s 73ms/step - loss: 0.4167 - accuracy: 0.8108 - val_loss: 0.4339 - val_accuracy: 0.8022
Epoch 51/100
313/313 [==============================] - 23s 73ms/step - loss: 0.4175 - accuracy: 0.8084 - val_loss: 0.4337 - val_accuracy: 0.8010
```

```python
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
```

![download1](https://user-images.githubusercontent.com/96654391/176169780-a6a9ddd0-1c34-4e65-93c3-008319020801.png)

Í∑∏ÎûòÎèÑ ÎÇòÎ¶Ñ Í≥ºÎåÄÏ†ÅÌï©ÏùÑ Ïûò Ï†úÏñ¥ÌïúÎìØ? => LSTM + ÎìúÎ°≠ÏïÑÏõÉ + 2Í∞úÏùò Ï∏µ ÏÇ¨Ïö©

## üîÆ GRU Íµ¨Ï°∞

GRUÎäî Gated Recurrent UnitÏùò ÏïΩÏûêÎ°ú LSTMÏùÑ Í∞ÑÏÜåÌôîÌïú Î≤ÑÏ†ÑÏúºÎ°ú ÏÉùÍ∞ÅÌï† Ïàò ÏûàÎã§. ÌïòÏßÄÎßå LSTM Ï≤òÎüº ÏÖÄ ÏÉÅÌÉúÎ•º Í≥ÑÏÇ∞ÌïòÏßÄ ÏïäÍ≥† ÏùÄÎãâ ÏÉÅÌÉú ÌïòÎÇòÎßå Ìè¨Ìï®ÌïòÍ≥† ÏûàÎã§. <br>

GRU ÏÖÄÏóêÎäî ÏùÄÎãâ ÏÉÅÌÉúÏôÄ ÏûÖÎ†•Ïóê Í∞ÄÏ§ëÏπòÎ•º Í≥±ÌïòÍ≥† Ï†àÌé∏ÏùÑ ÎçîÌïòÎäî ÏûëÏùÄ ÏÖÄÏù¥ 3Í∞úÍ∞Ä ÏûàÎã§. 2Í∞úÎäî ÏãúÍ∑∏Î™®Ïù¥Îìú ÌôúÏÑ±Ìôî Ìï®ÏàòÎ•º ÏÇ¨Ïö©ÌïòÍ≥† ÌïòÎÇòÎäî tanh ÌôúÏÑ±Ìôî Ìï®ÏàòÎ•º ÏÇ¨Ïö©ÌïúÎã§.

### 2Ô∏è‚É£ GRU Ïã†Í≤ΩÎßù ÎßåÎì§Í∏∞

```python
model4 = keras.Sequential()

model4.add(keras.layers.Embedding(500, 16, input_length=100))
model4.add(keras.layers.GRU(8))
model4.add(keras.layers.Dense(1, activation='sigmoid'))

model4.summary()

>>>
Model: "sequential_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_4 (Embedding)     (None, 100, 16)           8000

 gru (GRU)                   (None, 8)                 624

 dense_4 (Dense)             (None, 1)                 9

=================================================================
Total params: 8,633
Trainable params: 8,633
Non-trainable params: 0
_________________________________________________________________
```

### 3Ô∏è‚É£ GRU Ïã†Í≤ΩÎßù ÌõàÎ†®ÌïòÍ∏∞

```python
rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)
model4.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])

checkpoint_cb = keras.callbacks.ModelCheckpoint('best-gru-model.h5', save_best_only=True)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)

history = model4.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb])

>>>
Epoch 1/100
313/313 [==============================] - 15s 42ms/step - loss: 0.6925 - accuracy: 0.5242 - val_loss: 0.6922 - val_accuracy: 0.5374
Epoch 2/100
313/313 [==============================] - 13s 43ms/step - loss: 0.6906 - accuracy: 0.5932 - val_loss: 0.6901 - val_accuracy: 0.5876
Epoch 3/100
313/313 [==============================] - 13s 41ms/step - loss: 0.6874 - accuracy: 0.6143 - val_loss: 0.6860 - val_accuracy: 0.6146
Epoch 4/100
313/313 [==============================] - 13s 41ms/step - loss: 0.6817 - accuracy: 0.6309 - val_loss: 0.6791 - val_accuracy: 0.6220
Epoch 5/100
313/313 [==============================] - 12s 40ms/step - loss: 0.6713 - accuracy: 0.6457 - val_loss: 0.6664 - val_accuracy: 0.6390
Epoch 6/100
313/313 [==============================] - 12s 39ms/step - loss: 0.6528 - accuracy: 0.6611 - val_loss: 0.6435 - val_accuracy: 0.6670
Epoch 7/100
313/313 [==============================] - 12s 39ms/step - loss: 0.6172 - accuracy: 0.6867 - val_loss: 0.5956 - val_accuracy: 0.7072
Epoch 8/100
313/313 [==============================] - 12s 39ms/step - loss: 0.5499 - accuracy: 0.7315 - val_loss: 0.5349 - val_accuracy: 0.7432
Epoch 9/100
313/313 [==============================] - 12s 39ms/step - loss: 0.5137 - accuracy: 0.7531 - val_loss: 0.5166 - val_accuracy: 0.7530
Epoch 10/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4974 - accuracy: 0.7652 - val_loss: 0.5044 - val_accuracy: 0.7584
Epoch 11/100
313/313 [==============================] - 12s 40ms/step - loss: 0.4838 - accuracy: 0.7754 - val_loss: 0.4938 - val_accuracy: 0.7662
Epoch 12/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4742 - accuracy: 0.7823 - val_loss: 0.4858 - val_accuracy: 0.7706
Epoch 13/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4654 - accuracy: 0.7870 - val_loss: 0.4790 - val_accuracy: 0.7764
Epoch 14/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4588 - accuracy: 0.7914 - val_loss: 0.4736 - val_accuracy: 0.7772
Epoch 15/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4529 - accuracy: 0.7948 - val_loss: 0.4688 - val_accuracy: 0.7824
Epoch 16/100
313/313 [==============================] - 12s 40ms/step - loss: 0.4483 - accuracy: 0.7980 - val_loss: 0.4658 - val_accuracy: 0.7840
Epoch 17/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4440 - accuracy: 0.7999 - val_loss: 0.4629 - val_accuracy: 0.7868
Epoch 18/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4400 - accuracy: 0.8043 - val_loss: 0.4610 - val_accuracy: 0.7878
Epoch 19/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4367 - accuracy: 0.8043 - val_loss: 0.4597 - val_accuracy: 0.7890
Epoch 20/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4347 - accuracy: 0.8051 - val_loss: 0.4571 - val_accuracy: 0.7904
Epoch 21/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4321 - accuracy: 0.8071 - val_loss: 0.4555 - val_accuracy: 0.7896
Epoch 22/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4301 - accuracy: 0.8091 - val_loss: 0.4563 - val_accuracy: 0.7842
Epoch 23/100
313/313 [==============================] - 12s 40ms/step - loss: 0.4289 - accuracy: 0.8103 - val_loss: 0.4543 - val_accuracy: 0.7886
Epoch 24/100
313/313 [==============================] - 13s 43ms/step - loss: 0.4270 - accuracy: 0.8105 - val_loss: 0.4532 - val_accuracy: 0.7876
Epoch 25/100
313/313 [==============================] - 13s 40ms/step - loss: 0.4255 - accuracy: 0.8117 - val_loss: 0.4516 - val_accuracy: 0.7878
Epoch 26/100
313/313 [==============================] - 13s 41ms/step - loss: 0.4243 - accuracy: 0.8122 - val_loss: 0.4557 - val_accuracy: 0.7910
Epoch 27/100
313/313 [==============================] - 13s 40ms/step - loss: 0.4230 - accuracy: 0.8134 - val_loss: 0.4520 - val_accuracy: 0.7886
Epoch 28/100
313/313 [==============================] - 12s 40ms/step - loss: 0.4222 - accuracy: 0.8129 - val_loss: 0.4505 - val_accuracy: 0.7894
Epoch 29/100
313/313 [==============================] - 13s 41ms/step - loss: 0.4216 - accuracy: 0.8143 - val_loss: 0.4525 - val_accuracy: 0.7918
Epoch 30/100
313/313 [==============================] - 13s 41ms/step - loss: 0.4207 - accuracy: 0.8148 - val_loss: 0.4498 - val_accuracy: 0.7898
Epoch 31/100
313/313 [==============================] - 13s 40ms/step - loss: 0.4201 - accuracy: 0.8152 - val_loss: 0.4488 - val_accuracy: 0.7912
Epoch 32/100
313/313 [==============================] - 12s 39ms/step - loss: 0.4194 - accuracy: 0.8143 - val_loss: 0.4489 - val_accuracy: 0.7904
Epoch 33/100
313/313 [==============================] - 12s 40ms/step - loss: 0.4188 - accuracy: 0.8164 - val_loss: 0.4480 - val_accuracy: 0.7922
Epoch 34/100
313/313 [==============================] - 13s 40ms/step - loss: 0.4180 - accuracy: 0.8163 - val_loss: 0.4465 - val_accuracy: 0.7902
Epoch 35/100
313/313 [==============================] - 12s 40ms/step - loss: 0.4177 - accuracy: 0.8161 - val_loss: 0.4486 - val_accuracy: 0.7876
Epoch 36/100
313/313 [==============================] - 12s 40ms/step - loss: 0.4174 - accuracy: 0.8158 - val_loss: 0.4476 - val_accuracy: 0.7884
Epoch 37/100
313/313 [==============================] - 13s 40ms/step - loss: 0.4167 - accuracy: 0.8157 - val_loss: 0.4459 - val_accuracy: 0.7942
Epoch 38/100
313/313 [==============================] - 13s 40ms/step - loss: 0.4162 - accuracy: 0.8162 - val_loss: 0.4448 - val_accuracy: 0.7956
Epoch 39/100
313/313 [==============================] - 13s 41ms/step - loss: 0.4157 - accuracy: 0.8155 - val_loss: 0.4450 - val_accuracy: 0.7940
Epoch 40/100
313/313 [==============================] - 13s 41ms/step - loss: 0.4154 - accuracy: 0.8170 - val_loss: 0.4472 - val_accuracy: 0.7870
Epoch 41/100
313/313 [==============================] - 13s 41ms/step - loss: 0.4146 - accuracy: 0.8174 - val_loss: 0.4444 - val_accuracy: 0.7932
Epoch 42/100
313/313 [==============================] - 13s 41ms/step - loss: 0.4147 - accuracy: 0.8170 - val_loss: 0.4433 - val_accuracy: 0.7934
Epoch 43/100
313/313 [==============================] - 13s 42ms/step - loss: 0.4142 - accuracy: 0.8158 - val_loss: 0.4461 - val_accuracy: 0.7954
Epoch 44/100
313/313 [==============================] - 13s 43ms/step - loss: 0.4139 - accuracy: 0.8165 - val_loss: 0.4456 - val_accuracy: 0.7954
Epoch 45/100
313/313 [==============================] - 13s 42ms/step - loss: 0.4136 - accuracy: 0.8159 - val_loss: 0.4447 - val_accuracy: 0.7892
```

```python
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'val'])
plt.show()
```

![download2](https://user-images.githubusercontent.com/96654391/176172054-f505df07-0211-4a07-83fe-2a6e50964598.png)

ÎìúÎ°≠ÏïÑÏõÉÏùÑ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏïòÍ∏∞ ÎïåÎ¨∏Ïóê Ïù¥Ï†ÑÎ≥¥Îã§ ÌõàÎ†® ÏÜêÏã§Í≥º Í≤ÄÏ¶ù ÏÜêÏã§Ïùò Ï∞®Ïù¥Í∞Ä ÏûàÏßÄÎßå Ïûò ÏàòÎ†¥Îêú Í≤ÉÏùÑ ÌôïÏù∏Ìï† Ïàò ÏûàÎã§.
