---
title: "[ML] Style Transfer 논문 리뷰"
excerpt: "[ML] Style Transfer 논문 리뷰"
categories: [ML]
tags: [ML, Python]
toc: true
toc_sticky: true
---

📌 [논문 리뷰](https://audrb1999.tistory.com/5) <br>
📌 [논문 리뷰 2](https://inhopp.github.io/paper/Paper1/)

## Style Transfer 요약

- 이전까지의 방식들은 low-level feature들만 사용이 가능, 이미지를 변형시켰을 때 결과 이미지에서 high-level feature들에는 변화가 없었다.
- CNN 필터를 사용하여 얻은 high-level feature들을 사용할 것이다.

## Style Transfer

- 스타일 전송을 위해서 pre-trained CNN 모델(VGG19) 사용
- 가중치를 업데이트 하는 것이 학습이 아니라 두 개의 이미지를 사용하여 한 개의 이미지를 업데이트 하는 것이 학습
- CNN의 가중치를 고정시키고 noise 이미지를 업데이트하는 방식 <br>

논문의 핵심 내용 <br>
- 이미지의 style을 어떻게 정의할 것인가?
- content와 style을 어떻게 reconstruction 할 것인가?

## Content Reconstruction

content 이미지를 reconstruction하기 위해 content loss 함수를 정의한다. <br>
이 함수는 L번째 convolution layer에 존재하는 i번째 필터에 대응하는 F matrix로 표현된다. <br>

여기서 모든 필터를 사용해 업데이트하지 않고 4번째 layer 필터만 이용해 reconstruction 한다. 깊은 layer 필터를 사용할수록 해상도는 떨어지고 더 넗은 영역을 커버한다. 여기서 해당 논문에서는 conv4를 사용하는데, conv4를 사용하는 이유는 <br>
![이미지](https://user-images.githubusercontent.com/96368476/153033127-d0c8ecb9-9b7c-4f4b-a934-1312b145aaca.jpg) <br>

위와 같다. <br>
보게 되면 conv2_2 필터의 경우는 색감만 적용이 된 것을 확인할 수 있지만 conv4_2의 경우는 해상도는 떨어지지만 더 자연스럽게 스타일을 표현한다. 