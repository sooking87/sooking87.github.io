---
title: "[week 3] Object Detection & Segmentation(3)"
excerpt: "[week 3] Object Detection & Segmentation(3)"
categories: [ML]
tags: [ML, Python]
toc: true
toc_sticky: true
---

ğŸ“Œ [Top Instance Segmentation Models](https://roboflow.com/models/instance-segmentation)

## ì½”ë©ì—ì„œ êµ¬ê¸€ ë“œë¼ì´ë¸Œ

1. ê²½ë¡œ ì„¤ì •(gdrive/MyDrive ê²½ë¡œë¡œ ì´ë™í•œë‹¤.)
   ```py
   from google.colab import drive
   drive.mount("/content/gdrive")
   ```
2. í´ë¡ í•˜ê³  ì‹¶ì€ ëª¨ë¸ì„ ë‹¤ìš´ ë°›ëŠ”ë‹¤. -> MyDriveì— í´ë¡ ë¨.
   ```py
   !git clone https://github.com/facebookresearch/detectron2.git
   ```
3. os ê²½ë¡œ ì„¤ì •
   ```py
   import os
   os.chdir("/content/gdrive/MyDrive/detectron2")
   ```

## COCO dataset ë‹¤ìš´ë°›ê¸°

```py
!pip install CocoDataset==0.1.2
!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip
!unzip /content/gdrive/MyDrive/annotations_trainval2014.zip
```

```py
from coco_dataset import coco_dataset_download as cocod
class_name='person'  #class name
images_count=50       #count of images
annotations_path='/content/gdrive/MyDrive/annotations/instances_train2014.json' #path of coco dataset annotations
#call download function
cocod.coco_dataset_download(class_name,images_count,annotations_path)
```

ê²½ë¡œ: `/content/gdrive/MyDrive/annotations_trainval2014.zip` <br>
ì´ë¯¸ì§€ê²½ë¡œ: `/content/gdrive/MyDrive/person/{image_name}`

## detectron2_refactor

ğŸ“Œ [detectron2 github](https://github.com/facebookresearch/detectron2) <br>

ëœë¤ ì»¬ëŸ¬ë¡œ ì´ë¯¸ì§€ ìœ„ì— ì¹ í•´ì§€ë„ë¡ ìˆ˜ì •

```py
def load_model(threshold):
  # Create and set model's config
  cfg = get_cfg()
  cfg.merge_from_file("/content/gdrive/MyDrive/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold
  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")

  # Create model
  predictor = DefaultPredictor(cfg)
  return predictor

def get_predictor(img_path, threshold):
  # Load image (np.array type)
  img = cv2.imread(img_path)

  # Inferrence
  outputs = predictor(img)
  return outputs

def random_colour_masks(image):
  colours = [[0, 255, 0],[0, 0, 255],[255, 0, 0],[0, 255, 255],[255, 255, 0],[255, 0, 255],[80, 70, 180],[250, 80, 190],[245, 145, 50],[70, 150, 250],[50, 190, 190]]
  r = np.zeros_like(image).astype(np.uint8)
  g = np.zeros_like(image).astype(np.uint8)
  b = np.zeros_like(image).astype(np.uint8)
  r[image == 1], g[image == 1], b[image == 1] = colours[random.randrange(0, 10)]
  coloured_mask = np.stack([r, g, b], axis=2)
  return coloured_mask

def instance_segmentation_api(img_path, threshold):
  img = cv2.imread(img_path)
  predictor = load_model(threshold)
  outputs = predictor(img)

  # Tensor: gpu -> cpu
  outputs['instances'] = outputs['instances'].to('cpu')

  masks = outputs['instances'].pred_masks
  # obj_mask = np.sum(np.asarray(masks.unsqueeze(-1)), 0)
  for i in range(len(masks)):
    rgb_mask = random_colour_masks(masks[i])
    img = cv2.addWeighted(img, 1, rgb_mask, 0.5, 0)
  plt.figure(figsize=(20, 20))
  plt.imshow(img)
  plt.xticks([])
  plt.yticks([])
  plt.show()
```

- [ê³µë¶€í•˜ë©° ì •ë¦¬í•´ë³´ëŠ” Detectron2 íŠœí† ë¦¬ì–¼ ğŸŒ  (2) - Model, Training, Evaluation, Yacs configs, Lazy configs](https://comlini8-8.tistory.com/88)

### Model Input Format

- image: (C, H, W) í¬ë©§ì˜ Tensor
- height, weight: ì›í•˜ëŠ” outputì˜ height, weight ê°’
- instances: í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” instance ê°ì²´(gt_boxes/gt_classes/gt_masks/gt_keypoints)
- sem_seg: sementic segì˜ GT
- proposal

### Model Output Format

- instances: pred_boxes/scores/pred_classes/pred_masks/pred_keypointsë¥¼ ê°–ëŠ”ë‹¤.

### threshold ìˆ˜ì •

0.1 <br>
![download](https://user-images.githubusercontent.com/96654391/230750832-6b616c91-b56e-4275-82b1-4ec68a3efcc0.png) <br>

0.2 <br>
![download](https://user-images.githubusercontent.com/96654391/230750836-1b156a9d-d2e2-4d3b-8ea9-5e08ec55ea5a.png) <br>

0.3 <br>
![download](https://user-images.githubusercontent.com/96654391/230750843-8f63cb0f-5568-44d3-8b90-867043cf79e9.png)<br>

0.4 <br>
![download](https://user-images.githubusercontent.com/96654391/230750847-9a01d1dd-64b8-4636-8b59-169eda0f40e4.png) <br>

0.5 <br>
![download](https://user-images.githubusercontent.com/96654391/230750854-335cbe9e-2fea-435a-84c6-a6615370efc4.png) <br>

0.6 <br>
![download](https://user-images.githubusercontent.com/96654391/230750856-c803b8be-4cdf-4517-b979-045ed4ac893d.png) <br>

0.7 <br>
![download](https://user-images.githubusercontent.com/96654391/230750857-86aab7b4-231e-423c-ab35-da9811ddfa84.png) <br>

0.8 <br>
![download](https://user-images.githubusercontent.com/96654391/230750865-42b86c9d-fb3e-4cbb-87e9-c0476d55d0b8.png) <br>

0.9 <br>
![download](https://user-images.githubusercontent.com/96654391/230750872-44508358-38ae-4fcf-926a-9fbb90f7d25c.png) <br>

## Mask R-CNN with torchvision

- [Mask R-CNN for Instance Segmentation Using Pytorch](https://www.analyticsvidhya.com/blog/2023/02/mask-r-cnn-for-instance-segmentation-using-pytorch/)

- [Instance Segmentation with PyTorch and Mask R-CNN](https://debuggercafe.com/instance-segmentation-with-pytorch-and-mask-r-cnn/)

- [Mask RCNN Pytorch â€“ Instance Segmentation](https://learnopencv.com/mask-r-cnn-instance-segmentation-with-pytorch/)

- [Train Mask R-CNN for Image Segmentation](https://pysource.com/2021/08/10/train-mask-r-cnn-for-image-segmentation-online-free-gpu/) -> ì´ê±° í•´ë³´ê³  ì‹¶ì€ë°,,,,, ë¼ë²¨ë§ ê°œê·€ì°® ã…

### Input and Output

- input: list of tensor images of shape (n, c, h, w), size of images need not be fixed
  - n: number of images
  - c: number of channels, RGB = 3
  - h: height of image
  - w: width of image
- output
  - coordinates of bounding boxes
  - labels of classes(input image, scores of the labels)
  - the masks

### Load Model

```py
# Model loading
from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights
import torchvision

model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)
model.eval()
```

### def get_prediction

```py
def get_prediction(img_path, threshold):
  img = Image.open(img_path)
  # converted to image tensor using PyTorch's transform
  transform = T.Compose([T.ToTensor()])
  img = transform(img)
  # passing image to model
  pred = model([img])
  # make return value: masks, pred_boxes, pred_class
  pred_score = list(pred[0]['scores'].detach().numpy())
  pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1]
  masks = (pred[0]['masks'] > 0.5).squeeze().detach().cpu().numpy()
  pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]
  pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]
  # ì°¾ì€ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ ì¤‘ threshold ì´ìƒë˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ê¹Œì§€ ì§œë¦„
  masks = masks[:pred_t+1]
  pred_boxes = pred_boxes[:pred_t+1]
  pred_class = pred_class[:pred_t+1]
  return masks, pred_boxes, pred_class
```

- pred êµ¬ì¡°: [{key: value}]
  - boxes
  - labels
  - scores
  - masks

### def random_colour_masks

```py
# The masks of each predicted object is given random colour from a set of 11 predefined colours for visualization of the masks
def random_colour_masks(image):
  colours = [[0, 255, 0],[0, 0, 255],[255, 0, 0],[0, 255, 255],[255, 255, 0],[255, 0, 255],[80, 70, 180],[250, 80, 190],[245, 145, 50],[70, 150, 250],[50, 190, 190]]
  r = np.zeros_like(image).astype(np.uint8)
  g = np.zeros_like(image).astype(np.uint8)
  b = np.zeros_like(image).astype(np.uint8)
  r[image == 1], g[image == 1], b[image == 1] = colours[random.randrange(0, 10)]
  coloured_mask = np.stack([r, g, b], axis=2)
  return coloured_mask
```

ëœë¤ ìƒ‰ê¹” ê²°ì •

### def instance_segmentation_api

```py
# instance_segmentation
def instance_segmentation_api(img_path, threshold=0.5, rect_th=1, text_size=0.4, text_th=1):
  masks, boxes, pred_cls = get_prediction(img_path, threshold)
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  for i in range(len(masks)):
    rgb_mask = random_colour_masks(masks[i])
    img = cv2.addWeighted(img, 1, rgb_mask, 0.5, 0)
    c1, c2 = (int(boxes[i][0][0]), int(boxes[i][0][1])), (int(boxes[i][1][0]), int(boxes[i][1][1]))
    cv2.rectangle(img, c1, c2, color=(0, 255, 0), thickness=rect_th)
    cv2.putText(img, pred_cls[i], c1, cv2.FONT_HERSHEY_SIMPLEX, text_size, (0, 255, 0), thickness=text_th)
  plt.figure(figsize=(20, 20))
  plt.imshow(img)
  plt.xticks([])
  plt.yticks([])
  plt.show()
```

ê²°ê³¼ë¬¼ ë³´ì—¬ì£¼ëŠ” í•¨ìˆ˜ <br>

![download](https://user-images.githubusercontent.com/96654391/230593750-930ee1a5-38c8-48dd-8596-3a46088ce62a.png) <br>

ì„±ëŠ¥ ê´œì°®ì€ ê²ƒ ê°™ì€ë°,,,,

## YOLOv8

ìšœë¡œ ë²„ì „ 8ì„ ì‚¬ìš©í•œ ëª¨ë¸ 2ê°œë¥¼ ì‚¬ìš©í•´ë´¤ëŠ”ë° ë‘˜ë‹¤ ì–´ë–»ê²Œ ì‹œê°í™”ë¥¼ í•˜ëŠ”ì§€ ëª¨ë¥´ê² ìŒ,, í•˜ë‚˜ëŠ” ì‹œê°í™”ê°€ ë˜ëŠ”ë° íŠ¹ì • ì‚¬ì§„ìœ¼ë¡œë§Œ ë˜ê³ , í•˜ë‚˜ëŠ” í…ì„œê°€ ë‚˜ì˜¤ê¸°ëŠ” í•˜ëŠ”ë° ê±”ë¥¼ ì–´ë–»ê²Œ ì´ë¯¸ì§€í™” í•˜ëŠ”ì§€ ëª¨ë¥´ê² ìŒ...
