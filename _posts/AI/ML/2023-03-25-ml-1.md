---
title: "[week 1] Object Detection & Segmentation(1)"
excerpt: "[week 1] Object Detection & Segmentation(1)"
categories: [ML]
tags: [ML, Python]
toc: true
toc_sticky: true
---

## 용어 정리

- stride: 필터를 몇 칸 이동할지
- padding: 필터를 사용하게 되면 원본 이미지의 크기보다 작아지게 되므로 이를 방지하기 위해서 이미지 픽셀 주변에 0으로 채우는 것
- pooling layer <br>
  - max pooling: 필터의 크기 안에서 값이 가장 큰 값을 가져오는 형식
  - avg pooling: 필터의 크기 안에서 값들의 평균을 가져오는 형식 <br>
    pooling layer를 사용하는 이유는 다운샘플링 뿐만 아니라 나타나려는 것을 확실히 알 수 있기 때문에 주로 max pooling을 사용한다. <br>
- filter: 커널이라고도 하는데 이미지의 특징을 추출하고(Convolution Layer), 특징을 강화하고 이미지의 크기를 축소(Pooling Layer)한다.

## Convolution Neural Network

A Convolutional Neural Network is made up of three main layers: <br>

1. The Convolutional Layers
2. The Pooling Layers
3. The Fully Connected Layers <br>

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/227612688-ab74cbba-b583-4214-803a-0d6c0c41730f.png"> <br>

### Convolutional Layers

입력으로서 이미지 텐서를 받고, 이미지 텐서에 특정 수의 컨볼루션 필터(커널)를 적용하고, 렐루 함수를 출력에 적용한다. <br>

이미지에서 패턴과 정보를 추출하는 것이 컨볼루션 레이어의 목적이다.

### Pooling Layers

- 이미지의 크기를 줄여서 파라미터와 컴퓨터 연산을 줄일 수 있다.
- 여러 픽셀을 단일 픽셀 값으로 결합해서 네트워크가 일반적이 되도록한다.(과적합 방지)

### Fully Connected Layers

flattened image vector(1-D 이미지 텐서)로 만든다. 이 레이어에서 Classification이 진행된다.

### 최종 CNN 네트워크

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/196020085-b2f382d6-1b72-43a8-bfa3-836aa8a37f65.png">

## CNN을 활용한 모델 정리

### AlexNet

- 2012년 도입된 최초의 Large scale CNN 모델
- 8 layers

### VGGNet

<img width="500" alt="download1" src="https://user-images.githubusercontent.com/96654391/196028312-7bf8e89a-cf88-41dc-af27-bddb6916346f.png"> <br>

- 2014년 ImageNet Challenge에서 GoogleLenet 다음으로 성능이 우수하고 강력한 네트워크
- VGG-16, VGG-19 -> 사용한 레이어의 개수에 따라 이름이 나뉜다.
- 8개의 layers는 AlexNet 네트워크를 사용 <br>

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/227617834-690205d5-05ba-40dd-8b33-0996385d2182.png"> <br>

- \[특징\] VGG 연구팀에서 깊이가 깊어질수록 성능이 좋아진다는 것을 발견 -> 필터의 크기를 3 \* 3으로 고정을 해서 네트워크의 깊이를 깊게 하였다. <br>

### GoogleNet

<img width="1000" alt="download2" src="https://user-images.githubusercontent.com/96654391/196028683-d014c41d-cfe8-4363-80e0-960b26417e66.png">

- 2014년 Classification Challenge에서 우승한 네트워크
- 22 Layers 사용(9개의 Inception 모듈)

#### Inception 모듈

<img width="1000" alt="download3" src="https://user-images.githubusercontent.com/96654391/196028872-63954318-9340-4160-9cda-ffacf41226bc.png"> <br>

- inception: 더 많은 레이어를 가질수 있도록 함.

### ResNet

<img src="https://miro.medium.com/max/1200/1*6hF97Upuqg_LdsqWY6n_wg.png"> <br>

<img width="600" alt="download1" src="https://user-images.githubusercontent.com/96654391/198944357-a29fce0b-8d95-41f3-a48e-b0bb12695d04.png"> <br>

- 깊이가 깊어질수록 경사가 소실되거나 폭발하는 문제를 해결하고자 함. -> Residual block -> conv층을 통과한 F(x)와 conv층을 통과하지 않은 X의 합을 이용
- 152 Layers

## Object Detection: 2-stage-detector

물체를 식별하는 classification 문제와 물체의 위치를 찾는 localization 문제를 합한 것인데, 1-stage-detector은 두 가지 task를 동시에 행하는 법이고, 2-stage-detector는 이 두 문제를 순차적으로 행하는 법이다. <br>

1-stage Detector가 비교적으로 빠르지만 정확도가 낮고 2-stage Detector가 비교적으로 느리지만 정확도가 높다.

- 2-stage Detector에는 R-CNN부터 Fast R-CNN, Faster R-CNN같은 R-CNN 계열이 대표적이다.
- 1-stage Detector에는 YOLO(You Only Look Once)계열과 SSD 계열 등이 포함된다.

### R-CNN

<img width="1000" alt="download2" src="https://user-images.githubusercontent.com/96654391/199777076-9778762d-9127-45f8-80f5-a1cfdd43157e.png"> <br>

- Region Proposal: 물체의 영역을 찾음

1. Regions of Interest(ROI)라고 부른다. 이 ROI에 대해서 다시 selective search를 통해서 2000개의 ROI를 받는다.
2. Convolution Network에 넣기 전에 크기를 조정해서 width와 height를 동일하게 한다. (warp)
3. Convolution Network -> feature 추출
4. 분류하기 위해서 SVM을 사용(binary classification) + bounding box의 4가지 값도 예측(regression)

### Fast R-CNN

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/199781665-f285054c-b094-44ef-a859-fcd3c1e1b39c.png"> <br>

R-CNN과 유사하지만 Regions of Interest(ROI)를 개별적으로 처리하는 것이 아니라 전체 이미지에 해당하는 것을 처리한다. <br>

문제점

- CPU 상에서 Region Proposal을 사용하기 때문에 여전히 bottleneck 발생 <br>

bottleneck이 뭐야,,,?

### Faster R-CNN

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/199792503-f7c2eca3-5ce3-4aa9-a774-358d8357c774.png"> <br>

Fast R-CNN의 문제점을 네트워크 자체가 own region proposals를 예측하도록 하여 해결하였다.

### 2-Stage 방식 정리

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/200124779-dfd39321-d1de-49a6-910c-1eb32db771c1.png"> <br>

- R-CNN <br>

  특징: Selective Search를 통해서 나온 2000개의 Crop을 각각에 대해서 피쳐 맵을 뽑기 뒤해서 CNN를 거쳐 bbox와 category를 예측한다. <br>

  문제점: 약 2000개 정도의 Crop이 각각 CNN을 통과해야되다보니 시간이 너무 오래걸린다.

- Fast R-CNN <br>

  특징: Selective Search를 통해서 나온 2000개의 Crop에 대해서 피쳐 맵을 뽑기 위해서 CNN을 한 번만 통과하여 사용한다. <br>

  문제점: R-CNN과 마찬가지로 Region Proposal을 CPU를 통해서 진행한다. -> 속도가 느리다.

- Faster R-CNN <br>

  특징: Region Propoal Network(RPN)을 GPU 상에서 진행한다. 이미지를 보고 어느 곳에 object가 있을지를 예측한다. <br>

<img width="1000" alt="download2" src="https://user-images.githubusercontent.com/96654391/200125206-33b1857e-95d3-4c4e-9c3e-a54710b77d7b.png"> <br>

## 성능 평가

### IOU

두 바운딩 박스가 겹치는 비율을 의미한다. 성능 평가를 위해서도 사용되지만 NMS에서도 많이 사용된다.

### NMS(Non Maximum Supperession)

객체 검출에서는 하나의 인스턴스에 하나의 bounding box가 적용되어야 할 때, 가장 많이 겹치는 것을 제외하고 나머지는 없애는 방식이다.

## Object Detection VS Segmentation

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/227757472-1311d023-0ea8-480d-8308-47a09afc95fe.png">

## 다음 주

- object detection: YOLO -> 개념 + 실습
- Semantic Segmentation VS Instance Segmentaion
- segmentation: U-Net -> 개념 + 실습
