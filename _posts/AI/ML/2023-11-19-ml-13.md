---
title: "[ML] GCP 배포(4) :: Compute Engine & Docker"
excerpt: "[ML] GCP 배포(4) :: Compute Engine & Docker"
categories: [ML]
tags: [ML, Python]
toc: true
toc_sticky: true
---

Compute Engine & SSH는 G.G,,,,,ㅎㅎㅎㅎㅎ <br>

FastAPI를 사용하여 모델을 실행할 수 있는 Docker 이미지를 만들려면 다음과 같은 단계를 따를 수 있습니다. 아래는 간단한 예시를 제시한 것이므로 실제 프로젝트에 맞게 수정하셔야 합니다.

## ✅ 1. FastAPI 애플리케이션 작성:

FastAPI를 사용하여 모델을 제공하는 Python 파일을 작성합니다. 예를 들어, app.py라는 파일에 다음과 같이 작성할 수 있습니다.

```python
Copy code
from fastapi import FastAPI
from fastapi.responses import JSONResponse
import your_model_library # 모델 라이브러리 불러오기

app = FastAPI()

@app.post("/predict")
async def predict(data: dict): # 여기에서 모델을 사용하여 예측 수행
prediction = your_model_library.predict(data)

    return JSONResponse(content={"prediction": prediction})
```

## ✅ 2. Dockerfile 작성:

```Dockerfile
Copy code
FROM your_base_image

# 필요한 작업 수행

COPY . /app
WORKDIR /app

# FastAPI 및 필요한 라이브러리 설치

RUN pip install fastapi uvicorn

# 예시: Python 애플리케이션을 실행

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
여기서 your_base_image는 사용하는 베이스 이미지(예: python:3.8)입니다.
```

## ✅ 3. Docker 이미지 빌드:

```bash
docker build -t YOUR_LOCAL_DOCKER_IMAGE .
```

여기서 `YOUR_LOCAL_DOCKER_IMAGE` 는 생성할 Docker 이미지의 이름입니다.

## ✅ 4. Docker 이미지 저장:

다음 명령을 사용하여 생성한 Docker 이미지를 tar 아카이브로 저장합니다.

```bash
docker save -o YOUR_LOCAL_DOCKER_IMAGE.tar.gz YOUR_LOCAL_DOCKER_IMAGE
```

여기서 `YOUR_LOCAL_DOCKER_IMAGE.tar.gz` 는 생성한 Docker 이미지를 저장할 tar 아카이브의 이름입니다.

## 5. GCP Compute Engine 인스턴스로 복사 및 실행:

생성한 Docker 이미지를 GCP Compute Engine 인스턴스로 복사하고 실행합니다.

```bash
# SDK에서 진행
gcloud compute scp YOUR_LOCAL_DOCKER_IMAGE.tar.gz INSTANCE_NAME:~
-> gcloud compute scp C:\STUDY\6학기\docker-fast-style-transfer\test-style-transfer.tar.gz instance-practice:~ --zone="asia-east1-b"
gcloud compute ssh INSTANCE_NAME
-> gcloud compute ssh instance-practice --zone="asia-east1-b"

❗일단은 여기까지 진행 아래 docker load는 모르겟당,,,,,

# 인스턴스 내부에서 Docker 이미지 로드 및 실행

docker load -i YOUR_LOCAL_DOCKER_IMAGE.tar.gz
docker run -p 8000:8000 YOUR_LOCAL_DOCKER_IMAGE
```

여기서 `INSTANCE_NAME` 은 GCP Compute Engine 인스턴스의 이름입니다.

이제 FastAPI를 사용하여 모델을 제공하는 Docker 이미지가 GCP Compute Engine 인스턴스에서 실행 중입니다. 해당 FastAPI 애플리케이션은 /predict 엔드포인트를 통해 모델을 호출하고 예측을 수행할 수 있습니다. <br>

그러면,,, 그냥

- cloud function에서 storage 트리거 사용해서 compute engine 불러
- compute engine에서 docker 이미지 돌리기
- ✅ 결과 storage로 저장 -> ☑️ 변환 이미지 저장할 버킷 지정 및 url, 경로 지정 필요

## docker 이미지 제작 전 수정해야되는 코드 부분(오늘 TO DO)

✅ 그냥 CMD `--in-path` 에서 url 이미지 입력을 할 수 있게끔! <br>
✅ 그냥 CMD `--out-path` 는 지우기 <br>
☑️ json 파일이 업로드 된다면 cloud function에서 style_type이랑 img_name을 compute engine으로 전달
☑️ main.py 작성 (일단은 data 전달이 된 상태임을 가정, wave style type만 dockerfile로 배포하기로..)
