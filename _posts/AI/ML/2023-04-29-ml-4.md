---
title: "[week 4] Text-to-Image Generator(1)"
excerpt: "[week 4] Text-to-Image Generator(1)"
categories: [ML]
tags: [ML, Python]
toc: true
toc_sticky: true
---

## Architecture

The **_text encoding step_** may be performed with a recurrent neural network such as a long short-term memory (LSTM) network, though transformer models have since become a more popular option. <br>

-> RNN: <br>
-> LSTM: <br>
-> transformer models: <br>

For the **_image generation step_** , conditional generative adversarial networks have been commonly used, with diffusion models. <br>

-> diffusion models: Diffusion Models are a class of generative models, meaning that they are used to generate novel data, often images. 노이즈를 제거하면서 학습을 한다. <br>
diffusion model == the noise prediction model <br>
주로 U-Net 사용 <br>
![Alt text](https://www.assemblyai.com/blog/content/images/size/w1000/2022/07/arch-4.png) <br>

### Architecture Overview

Text Encoder : To encode text data into text embeddings <br>

Prior: Using text embeddings , generate image embeddings (the bridge) <br>

Decoder: Generating image using image embeddings <br>
![Alt text](https://miro.medium.com/v2/resize%3Afit%3A786/format%3Awebp/1%2AxAAnG-DxBMKGae6AnLWyUg.png)

## DALL-E

### Background

<img width="1000" alt="download1" src="https://user-images.githubusercontent.com/96654391/235330320-41c0c489-311a-4910-bc4d-dc9c32aec191.png"> <br>

문장 전체에 대해 인코딩을 하고 이미지를 생성했는데, 이렇게 된다면 word 레벨에서 정보가 소실될 수 있는 단점이 있다. <br>
따라서 word 레벨의 정보까지 사용하여 이미지를 만드는 네트워크가 Attentional Generative Network 이다. <br>
DASAM에서는 이미지의 일부와 문장의 일부를 매핑한 후, 유사도를 계산한다. <br>
<img width="1000" alt="download2" src="https://user-images.githubusercontent.com/96654391/235330445-3716fbbd-f581-4250-a765-831eba30ffeb.png"> <br>

- e: local text
- **e** : global text
- f: local feature
- **f** : global feature

### Methodology

- stage1:
  - Discete VAE 를 이용해서 256\*256 RGB 이미지를 32\*32 Image Token으로 압축
- stage2:
  - 최대 256 BPE-encoded text toekns을 32\*32 Image Token과 Concatenate
  - Text & Image token의 결합 분포 Modeling 하는 Autoregressive transformer 학습 <br>

<img width="1000" alt="download3" src="https://user-images.githubusercontent.com/96654391/235330769-738d8464-a5ed-4db4-8e5a-247e9428c3d8.png"> <br>
