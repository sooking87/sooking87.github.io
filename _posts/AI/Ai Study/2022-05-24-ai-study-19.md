---
title: "[chap 8-2] í•©ì„±ê³± ì‹ ê²½ë§ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ë¥˜"
excerpt: "[chap 8-2] í•©ì„±ê³± ì‹ ê²½ë§ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ë¥˜"
categories: [Ai Study]
tags: [Ai Study, Python]
toc: true
toc_sticky: true
---

## 1ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

```python
from tensorflow import keras
from sklearn.model_selection import train_test_split
(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()
train_scaled = train_input.reshape(-1, 28, 28, 1) / 255.0
train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)
```

## 2ï¸âƒ£ í•©ì„±ê³± ì‹ ê²½ë§ ë§Œë“¤ê¸°

```python
model = keras.Sequential()
# í•©ì„±ê³± ì¸µ 32ê°œ ë§Œë“¤ê¸°
model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(28, 28, 1)))
# í’€ë§
model.add(keras.layers.MaxPooling2D(2))
# í•©ì„±ê³± ì¸µ 64ê°œ ë§Œë“¤ê¸°
model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same', input_shape=(28, 28, 1)))
# í’€ë§
model.add(keras.layers.MaxPooling2D(2))

# ì€ë‹‰ì¸µ, ì¶œë ¥ì¸µ êµ¬ì„±
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(100, activation='relu'))
model.add(keras.layers.Dropout(0.4))
model.add(keras.layers.Dense(10, activation='softmax'))

model.summary()

>>>
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 28, 28, 32)        320

 max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0
 )

 conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496

 max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0
 2D)

 flatten (Flatten)           (None, 3136)              0

 dense (Dense)               (None, 100)               313700

 dropout (Dropout)           (None, 100)               0

 dense_1 (Dense)             (None, 10)                1010

=================================================================
Total params: 333,526
Trainable params: 333,526
Non-trainable params: 0
_________________________________________________________________
```

ëª¨ë¸ êµ¬ì„± ë³´ê¸°

```python
keras.utils.plot_model(model, show_shapes=True)
```

![download1](https://user-images.githubusercontent.com/96654391/170020464-212ca843-34f1-419d-a291-905fa81bee62.png)

<br>

ì²« í•©ì„±ê³±ìœ¼ë¡œ (28, 28, 32) íŠ¹ì„± ë§µ ìƒì„± <br>
ğŸ”½
<br>
(2, 2) í’€ë§ -> (14, 14, 32)
<br>
ğŸ”½
<br>
í•„í„° 64ê°œì‚¬ìš© -> (14, 14, 64) íŠ¹ì„± ë§µ ìƒì„±
<br>
ğŸ”½
<br>
(2, 2) í’€ë§ -> (7, 7, 64)

## 3ï¸âƒ£ ëª¨ë¸ ì»´íŒŒì¼ê³¼ í›ˆë ¨

```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')
checkpoint_cb = keras.callbacks.ModelCheckpoint('best-cnn-model.h5', save_best_only=True)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)

history = model.fit(train_scaled, train_target, epochs=20, validation_data = (val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb])

>>>
Epoch 1/20
1500/1500 [==============================] - 66s 43ms/step - loss: 0.5237 - accuracy: 0.8120 - val_loss: 0.3200 - val_accuracy: 0.8809
Epoch 2/20
1500/1500 [==============================] - 62s 42ms/step - loss: 0.3450 - accuracy: 0.8777 - val_loss: 0.2833 - val_accuracy: 0.8988
Epoch 3/20
1500/1500 [==============================] - 62s 41ms/step - loss: 0.2965 - accuracy: 0.8932 - val_loss: 0.2616 - val_accuracy: 0.9028
Epoch 4/20
1500/1500 [==============================] - 62s 41ms/step - loss: 0.2617 - accuracy: 0.9047 - val_loss: 0.2388 - val_accuracy: 0.9106
Epoch 5/20
1500/1500 [==============================] - 61s 41ms/step - loss: 0.2389 - accuracy: 0.9134 - val_loss: 0.2262 - val_accuracy: 0.9137
Epoch 6/20
1500/1500 [==============================] - 61s 41ms/step - loss: 0.2181 - accuracy: 0.9207 - val_loss: 0.2157 - val_accuracy: 0.9202
Epoch 7/20
1500/1500 [==============================] - 61s 41ms/step - loss: 0.1985 - accuracy: 0.9268 - val_loss: 0.2172 - val_accuracy: 0.9171
Epoch 8/20
1500/1500 [==============================] - 89s 59ms/step - loss: 0.1844 - accuracy: 0.9316 - val_loss: 0.2278 - val_accuracy: 0.9180
```

Adam ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©, ModelCheckpoint ì½œë°±ê³¼ EarlyStopping ì½œë°± ì‚¬ìš© -> 8ë²ˆì§¸ì—ì„œ ì¢…ë£Œëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŒ <br>

ê·¸ë˜ì„œ ì„±ëŠ¥ í‰ê°€ë¥¼ í•´ë³´ë©´

```python
model.evaluate(val_scaled, val_target)

375/375 [==============================] - 7s 19ms/step - loss: 0.2157 - accuracy: 0.9202
```

ì„±ëŠ¥ë„ 9ë²ˆì§¸ ì—í¬í¬ë‘ ë¹„ìŠ·í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. <br>

ì˜ˆì¸¡ í™•ë¥  ì¶œë ¥

```python
preds = model.predict(val_scaled[0:1])
print(preds)

[[5.7871392e-15 1.3805922e-17 4.2262581e-18 2.6966329e-16 1.4632787e-16
  1.2062244e-17 3.3623695e-16 3.4051947e-18 1.0000000e+00 2.8774577e-16]]
```

9ë²ˆì§¸ ê°’ì´ 1ì— ê·¼ì ‘ -> ì´ê²Œ ì–´ë–¤ ê°’ì˜ ë ˆì´ë¸”ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ

```python
classes = ['í‹°ì…”ì¸ ', 'ë°”ì§€', 'ìŠ¤ì›¨í„°', 'ë“œë ˆìŠ¤', 'ì½”íŠ¸', 'ìƒŒë‹¬', 'ì…”ì¸ ', 'ìŠ¤ë‹ˆì»¤ì¦ˆ', 'ê°€ë°©', 'ì•µí´ ë¶€ì¸ ']
import numpy as np
print(classes[np.argmax(preds)]) >> ê°€ë°©
```

ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.
